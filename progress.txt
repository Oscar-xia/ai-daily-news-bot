# Progress Log

## AI Daily News Bot - 项目进度记录

---

## 2026-02-14 - Task 10-13: AI 处理模块 ✓

### What was done:
- 创建 app/processors/filter.py - AI 初筛模块
- 创建 app/processors/summarizer.py - 摘要生成模块
- 创建 app/processors/classifier.py - 关键词提取和分类模块
- 创建 app/processors/scorer.py - 打分模块

### Features:
- AIFilter: 调用 LLM 判断新闻相关性，支持并发处理
- Summarizer: 生成 100 字以内的摘要
- Classifier: 提取 3-5 个关键词，自动分类 (AI/投资/Web3/混合)
- Scorer: 0-100 分打分，支持按分数排序

### Testing:
- 所有模块导入成功
- 结构验证通过

### Notes:
- 所有模块支持并发控制 (默认 5 个并发)
- 处理失败时有默认值保护
- 分类基于关键词匹配和 LLM 提取

---

## 2026-02-14 - Task 9: 去重模块 ✓

### What was done:
- 创建 app/processors/deduplicator.py
- 实现 URL 去重 (URL 标准化 + MD5 哈希)
- 实现标题相似度去重 (SequenceMatcher, 阈值 0.85)
- 实现 DeduplicationResult 数据类
- 支持 add_existing_items() 加载已有数据

### Testing:
- 测试 5 条数据，正确识别 2 条唯一、3 条重复
- URL 去重和标题去重都正常工作

### Notes:
- URL 标准化: 移除协议、www、跟踪参数、尾部斜杠
- 标题标准化: 小写、移除常见前缀 (Breaking, Just In)
- 相似度阈值可配置

---

## 2026-02-14 - Task 8: AI 搜索采集器 ✓

### What was done:
- 创建 app/collectors/search_collector.py
- 实现 Tavily API 调用
- 支持 6 个默认搜索关键词 (AI news, Web3 news, VC funding 等)
- 实现多关键词并发搜索 (search_multiple)

### Testing:
- 模块导入成功
- 结构验证通过
- 注意: 需要配置 TAVILY_API_KEY 才能使用

### Notes:
- 使用 settings.tavily_api_key 读取 API 密钥
- 支持自定义搜索关键词
- 返回结果包含 title, url, content

---

## 2026-02-14 - Task 7: Twitter 采集器 ✓

### What was done:
- 创建 app/collectors/twitter_collector.py
- 实现 RSSHub 调用 (通过 RSS 接口获取 Twitter)
- 支持配置多个 Twitter 用户 (collect_users, collect_from_config)
- 处理 Twitter 特有的数据格式 (HTML 清理)
- 添加速率限制保护 (并发限制为 3)

### Testing:
- 模块导入成功
- 结构验证通过
- 注意: 公共 RSSHub 实例可能被限流，建议自建或使用 Apify

### Notes:
- 使用 settings.twitter_user_list 读取配置的用户列表
- 自动清理 HTML 标签
- 支持从配置中读取分类

---

## 2026-02-14 - Task 6: RSS 采集器 ✓

### What was done:
- 创建 app/collectors/base.py 采集器基类 (CollectedItem, BaseCollector)
- 创建 app/collectors/rss_collector.py RSS 采集器
- 使用 feedparser 解析 RSS
- 实现错误处理和超时控制 (30秒)
- 支持 collect_many() 并发采集

### Testing:
- 测试 Hacker News RSS 源，成功采集 20 条信息
- 标题、URL、内容、作者、发布时间解析正确

### Notes:
- 使用 httpx 异步获取 RSS 内容
- 支持 RSS 2.0 和 Atom 格式
- 支持从 source.config 中读取分类信息

---

## 2026-02-14 - Task 5: Prompt 模板 ✓

### What was done:
- 创建 app/llm/prompts.py
- 实现 5 个 System Prompt 模板 (初筛、摘要、关键词、打分、早报生成)
- 实现 5 个 Prompt 生成函数 (get_filter_prompt, get_summary_prompt, get_keywords_prompt, get_score_prompt, get_report_prompt)
- 实现去重 Prompt (get_dedup_prompt)
- 实现 3 个响应解析函数 (parse_keywords_response, parse_score_response, parse_filter_response)

### Testing:
- 所有 Prompt 函数导入成功
- 解析函数测试通过

### Notes:
- 所有 Prompt 使用中文
- 早报生成支持按分类组织内容
- 解析函数具有容错能力，可处理多种响应格式

---

## 2026-02-14 - Task 4: LLM 基础封装 ✓

### What was done:
- 创建 app/llm/base.py LLM 基础模块
- 定义 BaseLLM 抽象基类
- 实现 OpenAILLM 类 (支持 OpenAI 兼容接口)
- 实现 ZhipuLLM 类 (智谱 AI)
- 实现错误处理和重试逻辑 (chat_with_retry)
- 实现 get_llm() 工厂函数，根据配置返回对应 LLM 实例
- 提供 chat() 和 simple_chat() 便捷函数

### Testing:
- 所有类和函数导入成功
- 模块结构验证通过

### Notes:
- 支持 3 种 LLM 提供商: OpenAI, 智谱, 通义千问
- 通义千问使用 OpenAI 兼容接口
- 重试逻辑: 最多 3 次，指数退避

---

## 2026-02-14 - Task 3: 数据库初始化 ✓

### What was done:
- 创建 scripts/init_db.py 数据库初始化脚本
- 创建所有数据表 (sources, raw_items, processed_items, reports, report_items)
- 插入 12 个默认 RSS 信息源配置 (AI 官方博客、社区、投资媒体、Web3 媒体)
- 测试数据库连接和基本 CRUD 操作

### Testing:
- python scripts/init_db.py 执行成功
- 验证数据库包含 12 条 Source 记录
- 所有表结构正确创建

### Notes:
- 需要安装 greenlet 库支持 SQLAlchemy 异步操作
- 已更新 requirements.txt 添加 greenlet 依赖
- 数据库文件: data/news.db (SQLite)

---

## 2026-02-14 - Task 2: 数据模型定义 ✓

### What was done:
- 创建 app/models/schemas.py
- 定义 Source 模型 (信息源配置，支持 rss/twitter/search)
- 定义 RawItem 模型 (原始信息，包含 source_id, title, content, url, status 等)
- 定义 ProcessedItem 模型 (处理后信息，包含 summary, keywords, score, approved 等)
- 定义 Report 模型 (早报，包含 report_date, content, status)
- 定义 ReportItem 模型 (早报与处理后信息的关联表)
- 创建 Pydantic Schema 用于 API 请求/响应

### Testing:
- 所有 SQLAlchemy 模型导入成功
- 所有 Pydantic Schema 导入成功

### Notes:
- 使用 SQLAlchemy 2.0 的 Mapped 类型注解
- 使用 CheckConstraint 约束枚举字段
- Pydantic 使用 ConfigDict(from_attributes=True) 替代旧版 Config

---

## 2026-02-14 - Task 1: 项目基础配置 ✓

### What was done:
- 创建项目目录结构 (app/, scripts/, data/, output/, logs/, tests/)
- 创建 requirements.txt (fastapi, uvicorn, feedparser, httpx, apscheduler, sqlalchemy, pydantic, python-dotenv, click, pytest)
- 创建 .env.example 环境变量模板
- 创建 app/config.py 配置管理模块 (使用 pydantic-settings)
- 创建 app/database.py 数据库连接模块 (使用 async SQLAlchemy)

### Testing:
- 运行 ./init.sh 成功创建虚拟环境和目录
- pip install -r requirements.txt 成功安装所有依赖
- 测试 app.config 和 app.database 模块导入成功

### Notes:
- Python 版本: 3.13.3
- 使用 aiosqlite 作为 SQLite 异步驱动
- 配置支持多种 LLM 提供商 (OpenAI, 智谱, 通义)

---

## 项目初始化

### 完成的工作:
- 创建项目目录 ai-daily-news-bot
- 初始化 Git 仓库
- 下载并修改架构文档 (architecture.md)
- 创建任务列表 (task.json)
- 配置工作流程文件

---
